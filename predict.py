# -*- coding: utf-8 -*-
"""predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11GkWN4HahDXcNEPeSY7SY07w1XPi6sW3
"""

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from skimage.feature import hog
from sklearn.externals import joblib

import torchvision
import copy
import pdb
import sys
import warnings
import time
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, models, transforms
import skimage.io
import skimage.transform
import skimage.color
import skimage

from PIL import Image

from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter,UnNormalizer, Normalizer
warnings.filterwarnings("ignore")

assert torch.__version__.split('.')[0] == '1'

# !cp -r '/content/drive/My Drive/Independent-Prj/models/retinanet' .
# !cp -r '/content/drive/My Drive/Independent-Prj/models/sampleUtilitiesCode' .

def draw_caption(image, box, caption):

    b = np.array(box).astype(int)
    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)
    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)

def resizer(image, min_side=608, max_side=1024):

    rows, cols, cns = image.shape

    smallest_side = min(rows, cols)

    # rescale the image so the smallest side is min_side
    scale = min_side / smallest_side

    # check if the largest side is now greater than max_side, which can happen
    # when images have a large aspect ratio
    largest_side = max(rows, cols)

    if largest_side * scale > max_side:
        scale = max_side / largest_side

    # resize the image with the computed scale
    image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))
    rows, cols, cns = image.shape

    pad_w = 32 - rows%32
    pad_h = 32 - cols%32

    new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)
    new_image[:rows, :cols, :] = image.astype(np.float32)
    
    return torch.from_numpy(new_image), scale

def predict(modelPath, imagePath, side, classes):
    mean = np.array([[[0.485, 0.456, 0.406]]])
    std = np.array([[[0.229, 0.224, 0.225]]])
    img = cv2.imread(imagePath)
    if side == 'R':
      img = cv2.flip(img, 1)
    image = (((img.astype(np.float32)/255.0)-mean)/std)
    image, scale = resizer(image)
    result = []
    
    retinanet = torch.load(modelPath)
    
    use_gpu = torch.cuda.is_available()
    if use_gpu:
        retinanet = retinanet.cuda()

    with torch.no_grad():
        st = time.time()
        scores, classification, transformed_anchors = retinanet(image.permute(2, 0, 1).cuda().float().unsqueeze(dim=0))
        tempScore = scores.cpu()
        tempClassification = classification.cpu()
        Nscore = tempScore.shape[0]
        tempDict = dict()
        transformed_anchors /= scale
        for i in range(classes):
            tempDict[i] = [0,-1]
        for i in range(0,Nscore):
            lab = int(tempClassification[i])
            labS = float(tempScore[i])
            if tempDict[lab][0] < labS:
                tempDict[lab][0] = labS
                tempDict[lab][1] = i
        

        for j in list(tempDict.keys()):
            bbox = transformed_anchors[tempDict[j][1],:]
            x1 = int(bbox[0])
            y1 = int(bbox[1])
            x2 = int(bbox[2])
            y2 = int(bbox[3])
            label_name = j+1 #As it will predict from 0-15 but we have our label naming from 1-16 if want from 1-16 then make it j+1
            result.append([x1,y1,x2,y2])
            # for visualization
            # draw_caption(img,(x1,y1,x2,y2),label_name)
            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=2)
    return result

def illum_correct(image):
    lab = cv2.cvtColor(image,cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    cl_image = clahe.apply(l)
    img1 = cv2.merge((cl_image,a,b))
    output_image = cv2.cvtColor(img1, cv2.COLOR_LAB2RGB)
    return output_image

def preprocess_img(image):
    gamma=0.8
    image_on_denoise = cv2.fastNlMeansDenoisingColored(image,None,9,9,7,21)
    illum_correct_image=illum_correct(image_on_denoise)
    gamma_corrected = np.array(255*(illum_correct_image / 255) ** gamma, dtype = 'uint8')
    return gamma_corrected

def color_hog_f(image):
    R=image[:,:,2]
    G=image[:,:,1]
    B=image[:,:,0]
    hist_R =hog(R,orientations=9,pixels_per_cell=(8,8),cells_per_block=(3,3))
    hist_G=hog(G,orientations=9,pixels_per_cell=(8,8),cells_per_block=(3,3))
    hist_B=hog(B,orientations=9,pixels_per_cell=(8,8),cells_per_block=(3,3))
    temp1=[]
    temp2=[]
    temp3=[]
    for j in range(len(hist_R)):
        temp1.append(hist_R[j])
        temp2.append(hist_G[j])
        temp3.append(hist_B[j])
    return temp3+temp2+temp1

def feature_extraction(image):
    hog_f = color_hog_f(image)
    rgb_f = image.flatten()
    return rgb_f

#Object Labels for LH and RH
label_LH = ['LH_mcp_E__ip', 'LH_pip_E__2', 'LH_pip_E__3', 'LH_pip_E__4', 'LH_pip_E__5', 
             'LH_mcp_E__1', 'LH_mcp_E__2', 'LH_mcp_E__3', 'LH_mcp_E__4', 'LH_mcp_E__5', 'LH_wrist_E__mc1', 
             'LH_wrist_E__mul', 'LH_wrist_E__nav', 'LH_wrist_E__lunate', 'LH_wrist_E__radius', 'LH_wrist_E__ulna']

label_RH = ['RH_mcp_E__ip', 'RH_pip_E__2', 'RH_pip_E__3', 'RH_pip_E__4', 'RH_pip_E__5', 
             'RH_mcp_E__1', 'RH_mcp_E__2', 'RH_mcp_E__3', 'RH_mcp_E__4', 'RH_mcp_E__5', 'RH_wrist_E__mc1', 
             'RH_wrist_E__mul', 'RH_wrist_E__nav', 'RH_wrist_E__lunate', 'RH_wrist_E__radius', 'RH_wrist_E__ulna']

#Object Labels for LF and RF
label_LF = ['LF_mtp_E__ip', 'LF_mtp_E__1',
            'LF_mtp_E__2', 'LF_mtp_E__3', 'LF_mtp_E__4', 'LF_mtp_E__5']

label_RF = ['RF_mtp_E__ip', 'RF_mtp_E__1', 'RF_mtp_E__2', 'RF_mtp_E__3',
            'RF_mtp_E__4', 'RF_mtp_E__5']

def mod_pred_val(val, joint):
  if joint == 'H':
    if val < 0:
      return 0
    else:
      if val <= 3:
        return int(np.floor(val))
      else:
        return 3
  else:
     if val < 0:
      return 0
     else:
       if val <= 3:
         return int(np.floor(val))
       else:
         return 3

all_columns = np.array(['Patient_ID', 'Overall_Tol', 'Overall_erosion',
       'Overall_narrowing', 'LH_mcp_E__ip', 'LH_pip_E__2', 'LH_pip_E__3',
       'LH_pip_E__4', 'LH_pip_E__5', 'LH_mcp_E__1', 'LH_mcp_E__2',
       'LH_mcp_E__3', 'LH_mcp_E__4', 'LH_mcp_E__5', 'LH_wrist_E__mc1',
       'LH_wrist_E__mul', 'LH_wrist_E__nav', 'LH_wrist_E__lunate',
       'LH_wrist_E__radius', 'LH_wrist_E__ulna', 'RH_mcp_E__ip',
       'RH_pip_E__2', 'RH_pip_E__3', 'RH_pip_E__4', 'RH_pip_E__5',
       'RH_mcp_E__1', 'RH_mcp_E__2', 'RH_mcp_E__3', 'RH_mcp_E__4',
       'RH_mcp_E__5', 'RH_wrist_E__mc1', 'RH_wrist_E__mul',
       'RH_wrist_E__nav', 'RH_wrist_E__lunate', 'RH_wrist_E__radius',
       'RH_wrist_E__ulna', 'LF_mtp_E__ip', 'LF_mtp_E__1', 'LF_mtp_E__2',
       'LF_mtp_E__3', 'LF_mtp_E__4', 'LF_mtp_E__5', 'RF_mtp_E__ip',
       'RF_mtp_E__1', 'RF_mtp_E__2', 'RF_mtp_E__3', 'RF_mtp_E__4',
       'RF_mtp_E__5', 'LH_pip_J__2', 'LH_pip_J__3', 'LH_pip_J__4',
       'LH_pip_J__5', 'LH_mcp_J__1', 'LH_mcp_J__2', 'LH_mcp_J__3',
       'LH_mcp_J__4', 'LH_mcp_J__5', 'LH_wrist_J__cmc3',
       'LH_wrist_J__cmc4', 'LH_wrist_J__cmc5', 'LH_wrist_J__mna',
       'LH_wrist_J__capnlun', 'LH_wrist_J__radcar', 'RH_pip_J__2',
       'RH_pip_J__3', 'RH_pip_J__4', 'RH_pip_J__5', 'RH_mcp_J__1',
       'RH_mcp_J__2', 'RH_mcp_J__3', 'RH_mcp_J__4', 'RH_mcp_J__5',
       'RH_wrist_J__cmc3', 'RH_wrist_J__cmc4', 'RH_wrist_J__cmc5',
       'RH_wrist_J__mna', 'RH_wrist_J__capnlun', 'RH_wrist_J__radcar',
       'RF_mtp_J__ip', 'LF_mtp_J__1', 'LF_mtp_J__2', 'LF_mtp_J__3',
       'LF_mtp_J__4', 'LF_mtp_J__5', 'LF_mtp_J__ip', 'RF_mtp_J__1',
       'RF_mtp_J__2', 'RF_mtp_J__3', 'RF_mtp_J__4', 'RF_mtp_J__5'])

image_folder = os.listdir("/content/drive/My Drive/Independent-Prj/models/test")
if 'template.csv' in image_folder:
  image_folder.remove('template.csv')
patient_prediction = {}
crp_size = (32,32)
for image in image_folder:
  print("Processing..", image)
  img = cv2.imread("/content/drive/My Drive/Independent-Prj/models/test/" + image)
  patient_id = image[:-7]
  overall_erosion = 0
  if patient_id not in patient_prediction:
    patient_prediction[patient_id] = {}
    for j in all_columns[48:]:
      patient_prediction[patient_id][j] = 0
  if image[8] == 'H':
    box_model = '/content/drive/My Drive/Independent-Prj/models/model_final_H.pt'
    box = predict(box_model, "/content/drive/My Drive/Independent-Prj/models/test/" + image, image[7], 16)
    for joint in range(0,16):
      newbb = box[joint]
      crop_img = img[newbb[1]:newbb[3], newbb[0]:newbb[2]]
      r,c,ch = crop_img.shape
      if r < 32 or c < 32:
        if image[7] == 'L':
          patient_prediction[patient_id][label_LH[joint]] = 0
        elif image[7] == 'R':
          patient_prediction[patient_id][label_RH[joint]] = 0        
      else:
        crop_img = cv2.resize(crop_img,crp_size)
        crop_img = feature_extraction(crop_img)
        reg_model_h = joblib.load('/content/drive/My Drive/Independent-Prj/models/cross_validation_models/linear/cv_reg_model_hand_1.pkl')
        val_pred = reg_model_h.predict([crop_img])
        val_pred = mod_pred_val(val_pred[0], 'H')
        overall_erosion += val_pred
        if image[7] == 'L':
          patient_prediction[patient_id][label_LH[joint]] = val_pred
        elif image[7] == 'R':
          patient_prediction[patient_id][label_RH[joint]] = val_pred
  elif image[8] == 'F':
    box_model = '/content/drive/My Drive/Independent-Prj/models/model_final_F.pt'
    box = predict(box_model, "/content/drive/My Drive/Independent-Prj/models/test/" + image, image[7], 6)
    for joint in range(0,6):
      newbb = box[joint]
      crop_img = img[newbb[1]:newbb[3], newbb[0]:newbb[2]]
      r,c,ch = crop_img.shape
      if r < 32 or c < 32:
        if image[7] == 'L':
          patient_prediction[patient_id][label_LF[joint]] = 0
        elif image[7] == 'R':
          patient_prediction[patient_id][label_RF[joint]] = 0        
      else:
        crop_img = cv2.resize(crop_img,crp_size)
        crop_img = feature_extraction(crop_img)
        reg_model_h = joblib.load('/content/drive/My Drive/Independent-Prj/models/cross_validation_models/linear/cv_reg_model_foot_1.pkl')
        val_pred = reg_model_h.predict([crop_img])
        val_pred = mod_pred_val(val_pred[0], 'F')
        overall_erosion += val_pred
        if image[7] == 'L':
          patient_prediction[patient_id][label_LF[joint]] = val_pred
        elif image[7] == 'R':
          patient_prediction[patient_id][label_RF[joint]] = val_pred
    patient_prediction[patient_id]['Overall_erosion'] = overall_erosion
    patient_prediction[patient_id]['Overall_Tol'] = overall_erosion
    patient_prediction[patient_id]['Overall_narrowing'] = 0

all_rows = []
for patient in patient_prediction:
  row = [patient]
  for col in all_columns[1:]:
    row.append(patient_prediction[patient][col])
  all_rows.append(row)

import csv
with open('/content/drive/My Drive/Independent-Prj/models/output/predictions.csv', 'w') as file:
  writer = csv.writer(file)
  writer.writerow(all_columns)
  for  row in all_rows:
    writer.writerow(row)